{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f4620-1beb-4ba3-81d3-ae9e8eb129ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RAG的基本流程和方法\n",
    "1、使用langchain的document_load来加载文本\n",
    "2、使用text_split来分割文本\n",
    "3、加载为document类型数据\n",
    "4、embedding成向量\n",
    "5、使用chorma和fassio来存储向量（非持久性，存在内存中）\n",
    "6、可以将向量存在splite中做永久性储存\n",
    "7、检索策略\n",
    "\"\"\"\n",
    "%run model.ipynb\n",
    "%run utils.ipynb\n",
    "%run retriever_methods.ipynb\n",
    "%run deal_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a8eb0-da77-4bdd-b433-545d334823ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''stored embedding'''\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "# 文件列表\n",
    "file_list = acq_filenames(\"group_txt_file\")\n",
    "\n",
    "# 读取并分割内容\n",
    "docs_list = []\n",
    "for file in tqdm(file_list):\n",
    "    \n",
    "    if file.split(\"/\")[1] == \"payloads.jsonl\":\n",
    "        docs = payload_deal(file)\n",
    "        for item in docs:\n",
    "            docs_list.append(item)\n",
    "    elif file.endswith(\".jsonl\"):\n",
    "        docs = jsonl2doc(file)\n",
    "        # 将分割的文本进行处理\n",
    "        for item in docs:\n",
    "            docs_list.append(item)\n",
    "    elif file.endswith(\".json\"):\n",
    "        docs = json2doc(file)\n",
    "        for item in docs:\n",
    "            docs_list.append(item)\n",
    "    elif file.endswith(\".pdf\"):\n",
    "        docs = pdf2doc(file)\n",
    "        for item in docs:\n",
    "            docs_list.append(item)\n",
    "    elif file.endswith(\".txt\"):\n",
    "        docs = txt2doc(file) \n",
    "        for item in docs:\n",
    "            docs_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb93bf-78e0-4956-97cf-8990c058efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_documents = SentenceWindow().metadata_format(docs_list, split_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf95fa-7be9-4051-9419-fb6e613e4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将处理好的文本储存进数据库\n",
    "vector_store = permanent_stored(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8221b3-07d4-4877-a400-70809b59e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''查询'''\n",
    "import time\n",
    "from langchain.prompts import PromptTemplate\n",
    "import sentence_transformers\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "s = time.time()\n",
    "# 获取Retriever\n",
    "def retriever_res(query):\n",
    "    embedding_model = \"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model, model_kwargs={'device': \"cuda:1\"})\n",
    "    embeddings.client = sentence_transformers.SentenceTransformer(embeddings.model_name, device=\"cuda:1\")\n",
    "    vector_store = Chroma(persist_directory='chroma_db_demo', embedding_function=embeddings)\n",
    "    \n",
    "    rag_retriver = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 2})\n",
    "    top_documents = SentenceWindow().search_and_format(rag_retriver, query)\n",
    "    return top_documents\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "        你是一名对答如流的专家，请根据如下的内容回答问题\n",
    "        {context}\n",
    "        请如实地回答用户所提出的问题:{question}，如果遇到你不知道的（包含在上述内容中也没有提到的），请回复“我不知道”。\n",
    "        \"\"\")\n",
    "\n",
    "# 使用句子窗口进行召回\n",
    "rag_chain = {\"context\": RunnableLambda(retriever_res), \"question\": RunnablePassthrough()} | prompt_template | local_model()\n",
    "\n",
    "# 提问&回答\n",
    "response = rag_chain.invoke(\"admin@338是什么\")\n",
    " \n",
    "print(response)\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
