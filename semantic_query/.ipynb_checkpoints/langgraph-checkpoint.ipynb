{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44869909-38fd-48f1-9067-1c303c9f4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------模型-----------------\n",
    "\n",
    "%run model.ipynb\n",
    "%run Tools.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ec4cecf-59fe-451d-b314-eb8f2787f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------tools--------------\n",
    "from langchain_core.tools import tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "import os \n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"aa75b60f3ae9dd286759062b9c2570fb6255c63c9678067617ad8628a7a4b1f4\"\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_weather(query : str):\n",
    "    \"\"\"这是一个查询天气的工具\"\"\"\n",
    "    \n",
    "    return search.run(query)\n",
    "    \n",
    "\n",
    "tools = tools + [search_weather, search_operate_book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93954870-f9bb-47c3-8927-e3869189b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "import os\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "model_with_tools = glm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        print(last_message.tool_calls)\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def graph_qa(question):\n",
    "    # Define a new graph\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    \n",
    "    # Define the two nodes we will cycle between\n",
    "    workflow.add_node(\"agent\", call_model)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "    \n",
    "    # Set the entrypoint as `agent`\n",
    "    # This means that this node is the first one called\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    \n",
    "    # We now add a conditional edge\n",
    "    workflow.add_conditional_edges(\n",
    "        # First, we define the start node. We use `agent`.\n",
    "        # This means these are the edges taken after the `agent` node is called.\n",
    "        \"agent\",\n",
    "        # Next, we pass in the function that will determine which node is called next.\n",
    "        should_continue,\n",
    "    )\n",
    "    \n",
    "    # We now add a normal edge from `tools` to `agent`.\n",
    "    # This means that after `tools` is called, `agent` node is called next.\n",
    "    workflow.add_edge(\"tools\", 'agent')\n",
    "    \n",
    "    # Initialize memory to persist state between graph runs\n",
    "    checkpointer = MemorySaver()\n",
    "    \n",
    "    # Finally, we compile it!\n",
    "    # This compiles it into a LangChain Runnable,\n",
    "    # meaning you can use it as you would any other runnable.\n",
    "    # Note that we're (optionally) passing the memory when compiling the graph\n",
    "    app = workflow.compile(checkpointer=checkpointer)\n",
    "    \n",
    "    # Use the Runnable\n",
    "    final_state = app.invoke(\n",
    "        {\"messages\": [SystemMessage(content=\"你是一个会调用工具函数的专家，请你根据用户问题，来调用工具进行回答\"), \n",
    "                      HumanMessage(content=question)]},\n",
    "        config={\"configurable\": {\"thread_id\": 42}}\n",
    "    )\n",
    "    #\"最近一天白菜还有多少？风机盘管1现在的温度怎么样？今天指挥室的温度是否异常？导航雷达的操作流程是什么？\"\n",
    "    return final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b497238-44b9-4ebc-be0e-19002f8ec1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'search_operate_book', 'args': {'query': '雨杂波功能是什么'}, 'id': 'call_2024081315280218ffcad01edb4098', 'type': 'tool_call'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'非常抱歉，我无法回答您的问题，因为调用工具时发生了内存错误。我建议您稍后再试或尝试其他问题。'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_qa(\"雨杂波功能是什么\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf276e1-174d-4d92-ad0f-25599d69bf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
