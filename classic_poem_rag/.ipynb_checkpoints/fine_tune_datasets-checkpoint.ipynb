{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfecd7-6b63-4e00-93f8-6085a5e4c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def delete_pdf_page(input_path, output_path, page_number):\n",
    "    with open(input_path, 'rb') as input_file:\n",
    "        reader = PyPDF2.PdfFileReader(input_file)\n",
    "        writer = PyPDF2.PdfFileWriter()\n",
    "\n",
    "        num_pages = reader.numPages\n",
    "\n",
    "        if page_number < 0 or page_number >= num_pages:\n",
    "            print(f\"Invalid page number. The PDF file has {num_pages} pages.\")\n",
    "            return\n",
    "\n",
    "        for current_page in range(num_pages):\n",
    "            if current_page != page_number:\n",
    "                page = reader.getPage(current_page)\n",
    "                writer.addPage(page)\n",
    "\n",
    "        with open(output_path, 'wb') as output_file:\n",
    "            writer.write(output_file)\n",
    "\n",
    "        print(f\"Page {page_number + 1} deleted successfully.\")\n",
    "\n",
    "# 示例用法\n",
    "input_path = 'input.pdf'  # 输入PDF文件路径\n",
    "output_path = 'output.pdf'  # 输出PDF文件路径\n",
    "page_number_to_delete = 2  # 要删除的页码（从0开始）\n",
    "\n",
    "delete_pdf_page(input_path, output_path, page_number_to_delete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "695a8622-94b8-40d9-9725-907035b9844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "import os\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"036549c5f123aa1a284cbd502edad88c.OpF6mns4FtQ4MaHO\"\n",
    "model = ChatZhipuAI(model=\"glm-4\",streamer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec5007d8-75da-4c2b-9993-17c099cacf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下的格式就可以让模板有大括号\n",
    "QA_PAIRS_SYSTEM_PROMPT = \"\"\"  \n",
    "<Context></Context> 标记中是一段文本，学习和分析它，并整理学习成果：  \n",
    "- 提出问题并给出每个问题的答案。  \n",
    "- 答案需详细完整，尽可能保留原文描述。  \n",
    "- 答案可以包含普通文字、链接、代码、表格、公示、媒体链接等 Markdown 元素。   \n",
    "\"\"\"\n",
    "\n",
    "QA_PAIRS_HUMAN_PROMPT = \"\"\"  \n",
    "请按以下json格式整理学习成果返回给我，不需要输出多余的话，符合json解析格式。:  \n",
    "<Context>  \n",
    "文本  \n",
    "</Context>  \n",
    "[  \n",
    "{{\"instruction\": \"问题1\",\"output\":\"答案1\"}},  \n",
    "{{\"instruction\": \"问题2\",\"output\":\"答案2\"}},  \n",
    "]  \n",
    "------  \n",
    "  \n",
    "我们开始吧!  \n",
    "  \n",
    "<Context>  \n",
    "{text}  \n",
    "<Context/>  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ff72d40-be66-458d-922a-ae62012daabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_document(filepath):  \n",
    "\tloader = UnstructuredFileLoader(filepath)  \n",
    "\ttext_spliter = RecursiveCharacterTextSplitter(  \n",
    "\t\tchunk_size=1024,  \n",
    "\t\tchunk_overlap=64  \n",
    "\t)  \n",
    "\tdocuments = loader.load_and_split(text_spliter)  \n",
    "\treturn documents\n",
    "\n",
    "def find_list(text):\n",
    "\n",
    "    # print(text.content)\n",
    "    # 正则表达式模式\n",
    "    pattern = r\"\\[.*?\\]\"\n",
    "    \n",
    "    # 使用 re.search 提取第一个匹配\n",
    "    match = re.search(pattern, text.content, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # 提取到的列表字符串\n",
    "        list_str = match.group(0)\n",
    "        return list_str  \n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5692f934-a42f-4035-83b0-72977e455e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [06:20,  2.49s/it]0:00<?, ?it/s]\n",
      " 18%|█▊        | 3/17 [00:15<01:13,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [00:27<00:49,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [00:37<00:23,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [00:52<00:06,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:02,  2.50s/it]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [01:14,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [01:27,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [01:40,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [01:52,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [02:06,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [02:18,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [02:30,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [02:41,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [02:54,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [03:08,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [03:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "from typing import List  \n",
    "  \n",
    "from tqdm import tqdm  \n",
    "from langchain_core.prompts import ChatPromptTemplate  \n",
    "from langchain_core.pydantic_v1 import BaseModel, Field  \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader  \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([  \n",
    "\t(\"system\", QA_PAIRS_SYSTEM_PROMPT),  \n",
    "\t(\"human\", QA_PAIRS_HUMAN_PROMPT)  \n",
    "])\n",
    "class QaPair(BaseModel):  \n",
    "\tinstruction: str = Field(description='问题内容')  \n",
    "\toutput: str = Field(description='问题的回答')  \n",
    "\n",
    "class QaPairs(BaseModel):  \n",
    "\tqas: List[QaPair] = Field(description='问答对列表')\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=QaPairs)\n",
    "\n",
    "chain = prompt | model | RunnableLambda(find_list) | parser\n",
    "\n",
    "documents = split_document('langchain_cainiao/text_file/poem/礼乐教化与《诗经》_吴贤哲.pdf')  \n",
    "\n",
    "with open(f'dataset.json', 'w', encoding='utf-8') as f:  \n",
    "    datas = []  \n",
    "    \n",
    "    bar = tqdm(total=len(documents))  \n",
    "    \n",
    "    for idx, doc in enumerate(documents):  \n",
    "        bar.update(idx + 1)\n",
    "        if doc.page_content:\n",
    "            # print(doc.page_content)\n",
    "            out = chain.invoke({'text': str(doc.page_content)})\n",
    "            out = [input_dict for input_dict in out if isinstance(input_dict, dict)] \n",
    "            print(True)\n",
    "            \n",
    "            datas += out\n",
    "    fulldatas = []\n",
    "    for data in datas:\n",
    "        data['input'] = ''\n",
    "        data['history'] = []\n",
    "        fulldatas.append(data)\n",
    "    f.write(json.dumps(fulldatas, ensure_ascii=False))  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238b374-285b-4d78-a320-3c923d696d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
