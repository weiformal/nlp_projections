{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dbfecd7-6b63-4e00-93f8-6085a5e4c727",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_pdf_page\u001b[39m(input_path, output_path, page_number):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m input_file:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def delete_pdf_page(input_path, output_path, page_number):\n",
    "    with open(input_path, 'rb') as input_file:\n",
    "        reader = PyPDF2.PdfFileReader(input_file)\n",
    "        writer = PyPDF2.PdfFileWriter()\n",
    "\n",
    "        num_pages = reader.numPages\n",
    "\n",
    "        if page_number < 0 or page_number >= num_pages:\n",
    "            print(f\"Invalid page number. The PDF file has {num_pages} pages.\")\n",
    "            return\n",
    "\n",
    "        for current_page in range(num_pages):\n",
    "            if current_page != page_number:\n",
    "                page = reader.getPage(current_page)\n",
    "                writer.addPage(page)\n",
    "\n",
    "        with open(output_path, 'wb') as output_file:\n",
    "            writer.write(output_file)\n",
    "\n",
    "        print(f\"Page {page_number + 1} deleted successfully.\")\n",
    "\n",
    "# 示例用法\n",
    "input_path = 'input.pdf'  # 输入PDF文件路径\n",
    "output_path = 'output.pdf'  # 输出PDF文件路径\n",
    "page_number_to_delete = 2  # 要删除的页码（从0开始）\n",
    "\n",
    "delete_pdf_page(input_path, output_path, page_number_to_delete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695a8622-94b8-40d9-9725-907035b9844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "import os\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"\"\n",
    "model = ChatZhipuAI(model=\"glm-4\",streamer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5007d8-75da-4c2b-9993-17c099cacf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下的格式就可以让模板有大括号\n",
    "QA_PAIRS_SYSTEM_PROMPT = \"\"\"  \n",
    "<Context></Context> 标记中是一段文本，学习和分析它，并整理学习成果：  \n",
    "- 根据不少于200字的文本提出问题并给出每个问题的答案。  \n",
    "- 答案需详细完整，尽可能保留原文描述，不少于150字。  \n",
    "- 答案可以包含普通文字、链接、代码、表格、公示、媒体链接等 Markdown 元素。   \n",
    "- 中文问题与答案\n",
    "\"\"\"\n",
    "\n",
    "QA_PAIRS_HUMAN_PROMPT = \"\"\"  \n",
    "请按以下json格式整理学习成果返回给我，不需要输出多余的话，符合json解析格式。:  \n",
    "<Context>  \n",
    "文本  \n",
    "</Context>  \n",
    "[  \n",
    "{{\"instruction\": \"问题1\",\"output\":\"答案1\"}},  \n",
    "{{\"instruction\": \"问题2\",\"output\":\"答案2\"}},  \n",
    "]  \n",
    "------  \n",
    "  \n",
    "我们开始吧!  \n",
    "  \n",
    "<Context>  \n",
    "{text}  \n",
    "<Context/>  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff72d40-be66-458d-922a-ae62012daabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_document(filepath):  \n",
    "\tloader = UnstructuredFileLoader(filepath)  \n",
    "\ttext_spliter = RecursiveCharacterTextSplitter(  \n",
    "\t\tchunk_size=2000,  \n",
    "\t\tchunk_overlap=64  \n",
    "\t)  \n",
    "\tdocuments = loader.load_and_split(text_spliter)  \n",
    "\treturn documents\n",
    "\n",
    "def find_list(text):\n",
    "\n",
    "    # print(text.content)\n",
    "    # 正则表达式模式\n",
    "    pattern = r\"\\[.*?\\]\"\n",
    "    \n",
    "    # 使用 re.search 提取第一个匹配\n",
    "    match = re.search(pattern, text.content, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # 提取到的列表字符串\n",
    "        list_str = match.group(0)\n",
    "        return list_str  \n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5692f934-a42f-4035-83b0-72977e455e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd01938b40f4d099996b291730e3512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json  \n",
    "from typing import List  \n",
    "  \n",
    "from tqdm.auto import tqdm  \n",
    "from langchain_core.prompts import ChatPromptTemplate  \n",
    "from langchain_core.pydantic_v1 import BaseModel, Field  \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader  \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([  \n",
    "\t(\"system\", QA_PAIRS_SYSTEM_PROMPT),  \n",
    "\t(\"human\", QA_PAIRS_HUMAN_PROMPT)  \n",
    "])\n",
    "class QaPair(BaseModel):  \n",
    "\tinstruction: str = Field(description='问题内容')  \n",
    "\toutput: str = Field(description='问题的回答')  \n",
    "\n",
    "class QaPairs(BaseModel):  \n",
    "\tqas: List[QaPair] = Field(description='问答对列表')\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=QaPairs)\n",
    "\n",
    "chain = prompt | model | RunnableLambda(find_list) | parser\n",
    "\n",
    "documents = split_document('poem/4.pdf')  \n",
    "\n",
    "with open(f'dataset.json', 'w', encoding='utf-8') as f:  \n",
    "    datas = []  \n",
    "    \n",
    "    \n",
    "    for doc in tqdm(documents):  \n",
    "        \n",
    "        if doc.page_content:\n",
    "            # print(doc.page_content)\n",
    "            out = chain.invoke({'text': str(doc.page_content)})\n",
    "            out = [input_dict for input_dict in out if isinstance(input_dict, dict)] \n",
    "            # print(True)\n",
    "            \n",
    "            datas += out\n",
    "    fulldatas = []\n",
    "    for data in datas:\n",
    "        data['input'] = ''\n",
    "        data['history'] = []\n",
    "        fulldatas.append(data)\n",
    "    f.write(json.dumps(fulldatas, ensure_ascii=False))  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238b374-285b-4d78-a320-3c923d696d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
